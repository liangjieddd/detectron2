# 准备数据集
1.在datasets/下新建文件夹coco
文件树：
~~~
coco 
  -annotations
      -instances_minival2014
      -instances_testdev2017
      -instances_train2014
  -minival2014
      -000005.jpg
      -000020.jpg
      -...
  -testdev2017
      -000025.jpg
      -000029.jpg
      -...
  -train2014
      -000001.jpg
      -000002.jpg
      -...
  __init__.py   #初始化
  visual_coco.py   #将注册后的数据集显示出来，随机选取几张图片
  ~~~
  
  2.修改配置文件：
    1.修改./detectron2/data/datasets/builtin_meta.py中的_get_coco_instances_meta()函数
      * COCO_CATEGORIES修改为对应的类别；
      * _get_coco_instances_meta函数中80->10
    2./home/dlj/detectron2/detectron2/data/datasets/builtin.py
      line124 coco
    3.config/Base-RCNN-FPN.yaml
      line33,34 2017->2014
  
  # 注册数据：
  projects/AL_Defect/register_data.py:
  ~~~
  from detectron2.data.datasets import register_coco_instances
  register_coco_instances("coco", {}, "/home/dlj/detectron2/datasets/coco/annotations/instances_train2014.json",
                        "/home/dlj/detectron2/datasets/coco/train2014")
  ~~~                      
 
 # 显示数据：
 projects/AL_Defect/visual_data.py
 ~~~
  import random
  from detectron2.utils.visualizer import Visualizer
  from detectron2.data.catalog import MetadataCatalog, DatasetCatalog
  import projects.AL_Defect.register_data
  import cv2

  coco_metadata = MetadataCatalog.get("coco")
  print(coco_metadata)
  dataset_dicts = DatasetCatalog.get("coco")

  for d in random.sample(dataset_dicts, 6):
      img = cv2.imread(d["file_name"])
      visualizer = Visualizer(img[:, :, ::-1], metadata=coco_metadata, scale=0.5)
      vis = visualizer.draw_dataset_dict(d)
      print(vis.get_image()[:, :, ::-1])
      img = vis.get_image()[:, :, ::-1]
      cv2.imshow('rr', img)
      cv2.waitKey(0)
  ~~~    
      
  data_loader.py
  ~~~
  import os
import numpy as np
import json
from detectron2.structures import BoxMode
import itertools
import cv2


# write a function that loads the dataset into detectron2's standard format
# img_dir = "coco_person"
def get_coco_dicts(img_dir):
    json_file = os.path.join(img_dir)
    with open(json_file) as f:
        imgs_anns = json.load(f)

    dataset_dicts = []
    for _, v in imgs_anns["images"].items():
        record = {}

        filename = os.path.join(img_dir, v["filename"])
        height, width = cv2.imread(filename).shape[:2]

        record["file_name"] = filename
        record["height"] = height
        record["width"] = width

        annos = v["regions"]
        objs = []
        for _, anno in annos.items():
            assert not anno["region_attributes"]
            anno = anno["shape_attributes"]
            px = anno["all_points_x"]
            py = anno["all_points_y"]
            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]
            poly = list(itertools.chain.from_iterable(poly))

            obj = {
                "bbox": [np.min(px), np.min(py), np.max(px), np.max(py)],
                "bbox_mode": BoxMode.XYXY_ABS,
                "segmentation": [poly],
                "category_id": 0,
                "iscrowd": 0
            }
            objs.append(obj)
        record["annotations"] = objs
        dataset_dicts.append(record)
    return dataset_dicts


from detectron2.data import DatasetCatalog, MetadataCatalog

for d in ["train", "val"]:
    DatasetCatalog.register("coco/" + d, lambda d=d: get_coco_dicts("coco/" + d))
    MetadataCatalog.get("coco/" + d).set(thing_classes=["coco"])
balloon_metadata = MetadataCatalog.get("coco/train")
~~~
      
  # 训练：
  projects/Al_Defect/train.py
  ~~~
  import random
from detectron2.utils.visualizer import Visualizer
from detectron2.data.catalog import MetadataCatalog, DatasetCatalog
import projects.AL_Defect.register_data
import cv2
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2.utils.logger import setup_logger
import os
setup_logger()

os.environ['CUDA_LAUNCH_BLOCKING'] = "1"

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

if __name__ == "__main__":

    cfg = get_cfg()
    cfg.merge_from_file(
        "/home/dlj/detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"
    )
    cfg.DATASETS.TRAIN = ("coco",)
    cfg.DATASETS.TEST = ()  # no metrics implemented for this dataset
    cfg.DATALOADER.NUM_WORKERS = 2
    # cfg.MODEL.WEIGHTS = "detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl"  # initialize from model zoo
    cfg.MODEL.WEIGHTS = "detectron2://ImageNetPretrained/MSRA/R-50.pkl"  # initialize from model zoo
    cfg.SOLVER.IMS_PER_BATCH = 2
    cfg.SOLVER.BASE_LR = 0.0025
    cfg.SOLVER.MAX_ITER = (2500)  # 300 iterations seems good enough, but you can certainly train longer
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)  # faster, and good enough for this toy dataset
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  # 3 classes (data, fig, hazelnut)

    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
    trainer = DefaultTrainer(cfg)
    trainer.resume_or_load(resume=False)
    trainer.train()
     ~~~
    
    

  


  
